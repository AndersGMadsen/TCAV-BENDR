{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "import mne, re, os\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR = 100.0\n",
    "#PARCELLATION = 'aparc.a2009s'\n",
    "PARCELLATION = 'HCPMMP1_combined'\n",
    "DATA_PATH = '/home/williamtheodor/Documents/DL for EEG Classification/data/'\n",
    "\n",
    "data_dict = load_mmidb_data_dict(DATA_PATH, PARCELLATION, SNR, chop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH_RAW = '../../data/eegmmidb (raw)/files/'\n",
    "DATA_PATH_CONCEPTS = '../../data/sanity check concepts MMIDB/'\n",
    "\n",
    "bands = data_dict.keys()\n",
    "patients_to_exclude = ['S088', 'S089', 'S090', 'S092', 'S104', 'S106']\n",
    "patients = [key for key in data_dict['Alpha'].keys() if key not in patients_to_exclude]\n",
    "runs = [key[-3:] for key in data_dict['Alpha'][patients[0]].keys() if key[-3:] not in ['R01', 'R02']]\n",
    "\n",
    "subjects_dir, subject, trans, src_path, bem_path = get_fsaverage()\n",
    "labels = get_labels(subjects_dir, parcellation_name=PARCELLATION)\n",
    "label_names = [label.name for label in np.array(labels).flatten()]\n",
    "\n",
    "bands = ['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label_idx in range(len(label_names)):\n",
    "    for band in bands:\n",
    "    # make directory if it doesn't exist\n",
    "        if not os.path.exists(f'{DATA_PATH_CONCEPTS}{band}_{label_names[label_idx]}'):\n",
    "            os.makedirs(f'{DATA_PATH_CONCEPTS}{band}_{label_names[label_idx]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 95/103 [08:07<00:41,  5.14s/it]/home/williamtheodor/Documents/DL for EEG Classification/BENDR-XAI/notebooks/utils.py:27: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_file_path, verbose=False, preload=True)\n",
      "/home/williamtheodor/Documents/DL for EEG Classification/BENDR-XAI/notebooks/utils.py:27: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_file_path, verbose=False, preload=True)\n",
      "/home/williamtheodor/Documents/DL for EEG Classification/BENDR-XAI/notebooks/utils.py:27: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_file_path, verbose=False, preload=True)\n",
      "/home/williamtheodor/Documents/DL for EEG Classification/BENDR-XAI/notebooks/utils.py:27: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_file_path, verbose=False, preload=True)\n",
      "/home/williamtheodor/Documents/DL for EEG Classification/BENDR-XAI/notebooks/utils.py:27: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_file_path, verbose=False, preload=True)\n",
      "/home/williamtheodor/Documents/DL for EEG Classification/BENDR-XAI/notebooks/utils.py:27: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_file_path, verbose=False, preload=True)\n",
      "/home/williamtheodor/Documents/DL for EEG Classification/BENDR-XAI/notebooks/utils.py:27: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_file_path, verbose=False, preload=True)\n",
      "/home/williamtheodor/Documents/DL for EEG Classification/BENDR-XAI/notebooks/utils.py:27: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_file_path, verbose=False, preload=True)\n",
      "/home/williamtheodor/Documents/DL for EEG Classification/BENDR-XAI/notebooks/utils.py:27: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_file_path, verbose=False, preload=True)\n",
      "/home/williamtheodor/Documents/DL for EEG Classification/BENDR-XAI/notebooks/utils.py:27: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_file_path, verbose=False, preload=True)\n",
      "/home/williamtheodor/Documents/DL for EEG Classification/BENDR-XAI/notebooks/utils.py:27: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_file_path, verbose=False, preload=True)\n",
      "/home/williamtheodor/Documents/DL for EEG Classification/BENDR-XAI/notebooks/utils.py:27: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_file_path, verbose=False, preload=True)\n",
      "100%|██████████| 103/103 [08:47<00:00,  5.12s/it]\n"
     ]
    }
   ],
   "source": [
    "NUMNER_PATIENTS = len(patients)\n",
    "NUMBER_RUNS = len(runs)\n",
    "NUMBER_WINDOWS = 15\n",
    "NUMBER_CHANNELS = 20\n",
    "\n",
    "NUMBER_BANDS = len(bands)\n",
    "NUMBER_LABELS = len(label_names)\n",
    "\n",
    "WINDOW_LENGTH = 4 # seconds\n",
    "SAMPLING_FREQ = 256 # Hz\n",
    "NUMBER_SAMPLES = int(WINDOW_LENGTH*SAMPLING_FREQ)\n",
    "\n",
    "\n",
    "\n",
    "baseline_run = 'R01' # baseline open eyes\n",
    "\n",
    "X = np.zeros((NUMNER_PATIENTS, NUMBER_RUNS, NUMBER_WINDOWS, NUMBER_CHANNELS, NUMBER_SAMPLES))\n",
    "Y = np.ones((NUMNER_PATIENTS, NUMBER_RUNS, NUMBER_WINDOWS)) * -1\n",
    "\n",
    "for patient in tqdm(patients):\n",
    "    baseline_activity = np.array([data_dict[band][patient][patient+baseline_run]['T0'] for band in bands]).reshape(NUMBER_BANDS, NUMBER_LABELS)\n",
    "\n",
    "    for run in runs:\n",
    "\n",
    "        FILE = DATA_PATH_RAW+f'{patient}/{patient}{run}.edf'\n",
    "\n",
    "        raw = get_raw(FILE)\n",
    "        annotations = get_annotations(FILE)\n",
    "\n",
    "        annotation_dict = get_window_dict(raw, annotations)\n",
    "\n",
    "        for key in ['T1', 'T2']:\n",
    "            for raw_idx, raw in enumerate(annotation_dict[key]):\n",
    "\n",
    "                raw = pick_and_rename_MMIDB_channels(raw)\n",
    "\n",
    "                activity = np.array([data_dict[band][patient][patient+run][key][raw_idx] for band in bands])\n",
    "                activity -= baseline_activity\n",
    "\n",
    "                most_active_band_idx = np.argmax(activity.mean(axis=1))\n",
    "                most_active_band = bands[most_active_band_idx]\n",
    "\n",
    "                brain_region_idx = activity[most_active_band_idx].argmax()\n",
    "                brain_region = label_names[brain_region_idx]\n",
    "\n",
    "                concept = most_active_band + '_' + brain_region       \n",
    "\n",
    "                \n",
    "                x = np.zeros((1, NUMBER_CHANNELS, NUMBER_SAMPLES))\n",
    "                x[:,:19,:] = raw.copy().get_data()[:,:NUMBER_SAMPLES].reshape(1,NUMBER_CHANNELS-1,NUMBER_SAMPLES)\n",
    "                x[:,19,:] = np.ones((1, NUMBER_SAMPLES)) * -1  \n",
    "                x = torch.from_numpy(x).float()\n",
    "                \n",
    "                picklePath = DATA_PATH_CONCEPTS + concept + '/' + patient + run + '_' + key + '_' + concept + '.pkl'\n",
    "                with open(picklePath, 'wb') as handle:\n",
    "                    pickle.dump(x, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['???-lh',\n",
       " 'Anterior Cingulate and Medial Prefrontal Cortex-lh',\n",
       " 'Auditory Association Cortex-lh',\n",
       " 'Dorsal Stream Visual Cortex-lh',\n",
       " 'DorsoLateral Prefrontal Cortex-lh',\n",
       " 'Early Auditory Cortex-lh',\n",
       " 'Early Visual Cortex-lh',\n",
       " 'Inferior Frontal Cortex-lh',\n",
       " 'Inferior Parietal Cortex-lh',\n",
       " 'Insular and Frontal Opercular Cortex-lh',\n",
       " 'Lateral Temporal Cortex-lh',\n",
       " 'MT+ Complex and Neighboring Visual Areas-lh',\n",
       " 'Medial Temporal Cortex-lh',\n",
       " 'Orbital and Polar Frontal Cortex-lh',\n",
       " 'Paracentral Lobular and Mid Cingulate Cortex-lh',\n",
       " 'Posterior Cingulate Cortex-lh',\n",
       " 'Posterior Opercular Cortex-lh',\n",
       " 'Premotor Cortex-lh',\n",
       " 'Primary Visual Cortex (V1)-lh',\n",
       " 'Somatosensory and Motor Cortex-lh',\n",
       " 'Superior Parietal Cortex-lh',\n",
       " 'Temporo-Parieto-Occipital Junction-lh',\n",
       " 'Ventral Stream Visual Cortex-lh',\n",
       " '???-rh',\n",
       " 'Anterior Cingulate and Medial Prefrontal Cortex-rh',\n",
       " 'Auditory Association Cortex-rh',\n",
       " 'Dorsal Stream Visual Cortex-rh',\n",
       " 'DorsoLateral Prefrontal Cortex-rh',\n",
       " 'Early Auditory Cortex-rh',\n",
       " 'Early Visual Cortex-rh',\n",
       " 'Inferior Frontal Cortex-rh',\n",
       " 'Inferior Parietal Cortex-rh',\n",
       " 'Insular and Frontal Opercular Cortex-rh',\n",
       " 'Lateral Temporal Cortex-rh',\n",
       " 'MT+ Complex and Neighboring Visual Areas-rh',\n",
       " 'Medial Temporal Cortex-rh',\n",
       " 'Orbital and Polar Frontal Cortex-rh',\n",
       " 'Paracentral Lobular and Mid Cingulate Cortex-rh',\n",
       " 'Posterior Cingulate Cortex-rh',\n",
       " 'Posterior Opercular Cortex-rh',\n",
       " 'Premotor Cortex-rh',\n",
       " 'Primary Visual Cortex (V1)-rh',\n",
       " 'Somatosensory and Motor Cortex-rh',\n",
       " 'Superior Parietal Cortex-rh',\n",
       " 'Temporo-Parieto-Occipital Junction-rh',\n",
       " 'Ventral Stream Visual Cortex-rh']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
