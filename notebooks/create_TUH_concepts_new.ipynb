{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "import mne, re, os, pickle, shutil\n",
    "import torch\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, minimum=-0.00125, maximum=0.00125):\n",
    "    return (x - minimum) / (maximum - minimum) * 2 - 1\n",
    "\n",
    "def save_concept(DATA_PATH_CONCEPTS, raw, concept, patient, run, idx, NUMBER_CHANNELS=20, NUMBER_SAMPLES=1024):\n",
    "\n",
    "    x = torch.zeros((1, NUMBER_CHANNELS, NUMBER_SAMPLES))\n",
    "    x[:, :NUMBER_CHANNELS-1, :] = torch.from_numpy(raw.copy().get_data()[:, :NUMBER_SAMPLES].reshape(1, NUMBER_CHANNELS-1, NUMBER_SAMPLES))\n",
    "    x = normalize(x)\n",
    "    x[:,NUMBER_CHANNELS-1,:] = torch.ones((1, NUMBER_SAMPLES)) * -1  \n",
    "    \n",
    "    picklePath = DATA_PATH_CONCEPTS + concept + '/' + patient + run + '_' + idx + '_' + concept + '.pkl'\n",
    "    with open(picklePath, 'wb') as handle:\n",
    "        pickle.dump(x, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def make_concepts_folders(DATA_PATH_CONCEPTS, bands_to_use, label_names):\n",
    "\n",
    "    # remove and remake concepts folder\n",
    "    print('Removing and remaking concepts folder: ', DATA_PATH_CONCEPTS)\n",
    "\n",
    "    if os.path.exists(DATA_PATH_CONCEPTS):\n",
    "        shutil.rmtree(DATA_PATH_CONCEPTS)\n",
    "    os.mkdir(DATA_PATH_CONCEPTS)\n",
    "\n",
    "    for label_idx in range(len(label_names)):\n",
    "        for band in bands_to_use:\n",
    "        # make directory if it doesn't exist\n",
    "            if not os.path.exists(f'{DATA_PATH_CONCEPTS}{band}_{label_names[label_idx]}'):\n",
    "                os.makedirs(f'{DATA_PATH_CONCEPTS}{band}_{label_names[label_idx]}')\n",
    "\n",
    "def save_concept(window, concept, DATA_PATH_CONCEPTS, edf_file, idx, NUMBER_CHANNELS=20, NUMBER_SAMPLES=1024):\n",
    "\n",
    "    x = torch.zeros((1, NUMBER_CHANNELS, NUMBER_SAMPLES))\n",
    "\n",
    "    x[:, :NUMBER_CHANNELS-1, :] = torch.from_numpy(window)\n",
    "    x[:,NUMBER_CHANNELS-1,:] = torch.ones((1, NUMBER_SAMPLES)) * -1  \n",
    "    \n",
    "    picklePath = DATA_PATH_CONCEPTS + concept + '/' + edf_file[:-4] + '_' + str(idx) + '_' + concept + '.pkl'\n",
    "    with open(picklePath, 'wb') as handle:\n",
    "        pickle.dump(x, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVITY_PATH = '/home/williamtheodor/Documents/DL for EEG Classification/data/Activity/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict(dict):\n",
    "    return {k: dict[k] for k in sorted(dict.keys())}\n",
    "\n",
    "PARCELLATION = 'HCPMMP1_combined'\n",
    "\n",
    "delta_activity = np.load(ACTIVITY_PATH + 'HCPMMP1_combined_1.0_4.0_213638_280423.npy', allow_pickle=True).item()\n",
    "theta_activity = np.load(ACTIVITY_PATH + 'HCPMMP1_combined_4.0_8.0_220344_280423.npy', allow_pickle=True).item()\n",
    "alpha_activity = np.load(ACTIVITY_PATH + 'HCPMMP1_combined_8.0_12.0_220503_280423.npy', allow_pickle=True).item()\n",
    "beta_activity = np.load(ACTIVITY_PATH + 'HCPMMP1_combined_12.0_30.0_222628_280423.npy', allow_pickle=True).item()\n",
    "gamma_activity = np.load(ACTIVITY_PATH + 'HCPMMP1_combined_30.0_70.0_225658_280423.npy', allow_pickle=True).item()\n",
    "\n",
    "activity_dict = {\n",
    "    'Delta': sort_dict(delta_activity),\n",
    "    'Theta': sort_dict(theta_activity),\n",
    "    'Alpha': sort_dict(alpha_activity),\n",
    "    'Beta': sort_dict(beta_activity),\n",
    "    'Gamma': sort_dict(gamma_activity)\n",
    "}\n",
    "\n",
    "bands = list(activity_dict.keys())\n",
    "edf_files = list(activity_dict[bands[0]].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing and remaking concepts folder:  /home/williamtheodor/Documents/DL for EEG Classification/data/tuh concepts/\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH_RAW = '/home/williamtheodor/Documents/DL for EEG Classification/data/tuh_eeg/'\n",
    "DATA_PATH_CONCEPTS = '/home/williamtheodor/Documents/DL for EEG Classification/data/tuh concepts/'\n",
    "\n",
    "NUMBER_CHANNELS = 20\n",
    "NUMBER_SAMPLES = 1024\n",
    "\n",
    "subjects_dir, subject, trans, src_path, bem_path = get_fsaverage()\n",
    "labels = get_labels(subjects_dir, parcellation_name=PARCELLATION)\n",
    "label_names = [label.name for label in np.array(labels).flatten()]\n",
    "\n",
    "make_concepts_folders(DATA_PATH_CONCEPTS, bands, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [03:16<00:00,  1.02it/s]\n"
     ]
    }
   ],
   "source": [
    "channel_order = [\n",
    "                'Fp1', 'Fp2',\n",
    "        'F7', 'F3', 'Fz', 'F4', 'F8',\n",
    "        'T3', 'C3', 'Cz', 'C4', 'T4',\n",
    "        'T5', 'P3', 'Pz', 'P4', 'T6',\n",
    "                 'O1', 'O2'\n",
    "    ]\n",
    "\n",
    "\n",
    "for edf_file in tqdm(edf_files, total=len(edf_files)): \n",
    "\n",
    "    x = edf_file\n",
    "\n",
    "    FILE = DATA_PATH_RAW + edf_file\n",
    "    raw = read_TUH_edf(FILE, low_pass=None)\n",
    "\n",
    "    try:\n",
    "        raw.reorder_channels(channel_order)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    annotations = activity_dict['Alpha'][edf_file]['annotations']['T0']\n",
    "\n",
    "    baseline_power = np.array([activity_dict[band][edf_file]['power']['T0'].mean(axis=0) for band in bands])\n",
    "    baseline_variance = np.array([activity_dict[band][edf_file]['variance']['T0'].mean(axis=0) for band in bands])\n",
    "\n",
    "    for idx, annotation in enumerate(annotations):\n",
    "        window = get_window(raw, annotation).get_data()\n",
    "        window = normalize(window)\n",
    "\n",
    "        power = np.array([activity_dict[band][edf_file]['power']['T0'][idx] for band in bands])\n",
    "        power = np.abs(power - baseline_power) / np.sqrt(baseline_variance)\n",
    "\n",
    "        most_active_band_idx = np.argmax(power.mean(axis=1))\n",
    "        most_active_band = bands[most_active_band_idx]\n",
    "\n",
    "        brain_region_idx = power[most_active_band_idx].argmax()\n",
    "        brain_region = label_names[brain_region_idx]\n",
    "\n",
    "        concept = most_active_band + '_' + brain_region\n",
    "\n",
    "        save_concept(window, concept, DATA_PATH_CONCEPTS, edf_file, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
