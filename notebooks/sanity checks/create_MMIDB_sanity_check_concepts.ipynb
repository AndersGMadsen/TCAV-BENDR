{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "import mne, re, os\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR = 100.0\n",
    "#PARCELLATION = 'aparc.a2009s'\n",
    "PARCELLATION = 'HCPMMP1_combined'\n",
    "DATA_PATH = '/home/williamtheodor/Documents/DL for EEG Classification/data/'\n",
    "\n",
    "data_dict = load_mmidb_data_dict(DATA_PATH, PARCELLATION, SNR, chop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH_RAW = '../../data/eegmmidb (raw)/files/'\n",
    "DATA_PATH_CONCEPTS = '../../data/sanity check concepts MMIDB desync/'\n",
    "\n",
    "bands = data_dict.keys()\n",
    "patients_to_exclude = ['S088', 'S089', 'S090', 'S092', 'S104', 'S106']\n",
    "patients = [key for key in data_dict['Alpha'].keys() if key not in patients_to_exclude]\n",
    "runs = ['R03', 'R04', 'R07', 'R08', 'R11', 'R12']\n",
    "\n",
    "subjects_dir, subject, trans, src_path, bem_path = get_fsaverage()\n",
    "labels = get_labels(subjects_dir, parcellation_name=PARCELLATION)\n",
    "label_names = [label.name for label in np.array(labels).flatten()]\n",
    "\n",
    "#bands = ['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma']\n",
    "bands = ['Alpha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label_idx in range(len(label_names)):\n",
    "    for band in bands:\n",
    "    # make directory if it doesn't exist\n",
    "        if not os.path.exists(f'{DATA_PATH_CONCEPTS}{band}_{label_names[label_idx]}'):\n",
    "            os.makedirs(f'{DATA_PATH_CONCEPTS}{band}_{label_names[label_idx]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 95/103 [04:05<00:20,  2.57s/it]/home/williamtheodor/Documents/DL for EEG Classification/BENDR-XAI/notebooks/utils.py:27: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_file_path, verbose=False, preload=True)\n",
      "/home/williamtheodor/Documents/DL for EEG Classification/BENDR-XAI/notebooks/utils.py:27: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_file_path, verbose=False, preload=True)\n",
      "/home/williamtheodor/Documents/DL for EEG Classification/BENDR-XAI/notebooks/utils.py:27: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_file_path, verbose=False, preload=True)\n",
      "/home/williamtheodor/Documents/DL for EEG Classification/BENDR-XAI/notebooks/utils.py:27: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_file_path, verbose=False, preload=True)\n",
      "/home/williamtheodor/Documents/DL for EEG Classification/BENDR-XAI/notebooks/utils.py:27: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_file_path, verbose=False, preload=True)\n",
      "/home/williamtheodor/Documents/DL for EEG Classification/BENDR-XAI/notebooks/utils.py:27: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_file_path, verbose=False, preload=True)\n",
      "100%|██████████| 103/103 [04:25<00:00,  2.58s/it]\n"
     ]
    }
   ],
   "source": [
    "NUMNER_PATIENTS = len(patients)\n",
    "NUMBER_RUNS = len(runs)\n",
    "NUMBER_WINDOWS = 15\n",
    "NUMBER_CHANNELS = 20\n",
    "\n",
    "NUMBER_BANDS = len(bands)\n",
    "NUMBER_LABELS = len(label_names)\n",
    "\n",
    "WINDOW_LENGTH = 4 # seconds\n",
    "SAMPLING_FREQ = 256 # Hz\n",
    "NUMBER_SAMPLES = int(WINDOW_LENGTH*SAMPLING_FREQ)\n",
    "\n",
    "\n",
    "baseline_run = 'R01' # baseline open eyes\n",
    "\n",
    "X = np.zeros((NUMNER_PATIENTS, NUMBER_RUNS, NUMBER_WINDOWS, NUMBER_CHANNELS, NUMBER_SAMPLES))\n",
    "Y = np.ones((NUMNER_PATIENTS, NUMBER_RUNS, NUMBER_WINDOWS)) * -1\n",
    "\n",
    "for patient in tqdm(patients):\n",
    "    #baseline_activity = np.array([data_dict[band][patient][patient+baseline_run]['T0'] for band in bands]).reshape(NUMBER_BANDS, NUMBER_LABELS)\n",
    "    baseline_activity = data_dict['Alpha'][patient][patient+baseline_run]['T0'].reshape(NUMBER_LABELS)\n",
    "\n",
    "    for run in runs:\n",
    "\n",
    "        FILE = DATA_PATH_RAW+f'{patient}/{patient}{run}.edf'\n",
    "\n",
    "        raw = get_raw(FILE)\n",
    "        annotations = get_annotations(FILE)\n",
    "\n",
    "        annotation_dict = get_window_dict(raw, annotations)\n",
    "\n",
    "        for key in ['T1', 'T2']:\n",
    "            for raw_idx, raw in enumerate(annotation_dict[key]):\n",
    "\n",
    "                raw = pick_and_rename_MMIDB_channels(raw)\n",
    "\n",
    "                #activity = np.array([data_dict[band][patient][patient+run][key][raw_idx] for band in bands])\n",
    "                activity = data_dict['Alpha'][patient][patient+run][key][raw_idx]\n",
    "                activity -= baseline_activity\n",
    "                activity = np.abs(activity)\n",
    "\n",
    "                #most_active_band_idx = np.argmax(activity.mean(axis=1))\n",
    "                #most_active_band = bands[most_active_band_idx]\n",
    "\n",
    "                #brain_region_idx = activity[most_active_band_idx].argmax()\n",
    "                brain_region_idx = activity.argmax()\n",
    "                brain_region = label_names[brain_region_idx]\n",
    "\n",
    "                #concept = most_active_band + '_' + brain_region \n",
    "                concept = 'Alpha_' + brain_region \n",
    "\n",
    "                \n",
    "                x = np.zeros((1, NUMBER_CHANNELS, NUMBER_SAMPLES))\n",
    "                x[:,:19,:] = raw.copy().get_data()[:,:NUMBER_SAMPLES].reshape(1,NUMBER_CHANNELS-1,NUMBER_SAMPLES)\n",
    "                x[:,19,:] = np.ones((1, NUMBER_SAMPLES)) * -1  \n",
    "                x = torch.from_numpy(x).float()\n",
    "                \n",
    "                picklePath = DATA_PATH_CONCEPTS + concept + '/' + patient + run + '_' + key + '_' + concept + '.pkl'\n",
    "                with open(picklePath, 'wb') as handle:\n",
    "                    pickle.dump(x, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha_???-lh: T1 = 0, T2 = 0\n",
      "Alpha_Anterior Cingulate and Medial Prefrontal Cortex-lh: T1 = 2, T2 = 0\n",
      "Alpha_Auditory Association Cortex-lh: T1 = 41, T2 = 43\n",
      "Alpha_Dorsal Stream Visual Cortex-lh: T1 = 18, T2 = 16\n",
      "Alpha_DorsoLateral Prefrontal Cortex-lh: T1 = 126, T2 = 128\n",
      "Alpha_Early Auditory Cortex-lh: T1 = 0, T2 = 0\n",
      "Alpha_Early Visual Cortex-lh: T1 = 19, T2 = 18\n",
      "Alpha_Inferior Frontal Cortex-lh: T1 = 190, T2 = 199\n",
      "Alpha_Inferior Parietal Cortex-lh: T1 = 7, T2 = 7\n",
      "Alpha_Insular and Frontal Opercular Cortex-lh: T1 = 0, T2 = 0\n",
      "Alpha_Lateral Temporal Cortex-lh: T1 = 5, T2 = 4\n",
      "Alpha_MT+ Complex and Neighboring Visual Areas-lh: T1 = 44, T2 = 42\n",
      "Alpha_Medial Temporal Cortex-lh: T1 = 0, T2 = 0\n",
      "Alpha_Orbital and Polar Frontal Cortex-lh: T1 = 300, T2 = 312\n",
      "Alpha_Paracentral Lobular and Mid Cingulate Cortex-lh: T1 = 7, T2 = 8\n",
      "Alpha_Posterior Cingulate Cortex-lh: T1 = 0, T2 = 0\n",
      "Alpha_Posterior Opercular Cortex-lh: T1 = 11, T2 = 7\n",
      "Alpha_Premotor Cortex-lh: T1 = 10, T2 = 18\n",
      "Alpha_Primary Visual Cortex (V1)-lh: T1 = 6, T2 = 4\n",
      "Alpha_Somatosensory and Motor Cortex-lh: T1 = 5, T2 = 4\n",
      "Alpha_Superior Parietal Cortex-lh: T1 = 49, T2 = 46\n",
      "Alpha_Temporo-Parieto-Occipital Junction-lh: T1 = 7, T2 = 7\n",
      "Alpha_Ventral Stream Visual Cortex-lh: T1 = 0, T2 = 0\n",
      "Alpha_???-rh: T1 = 0, T2 = 0\n",
      "Alpha_Anterior Cingulate and Medial Prefrontal Cortex-rh: T1 = 0, T2 = 0\n",
      "Alpha_Auditory Association Cortex-rh: T1 = 46, T2 = 50\n",
      "Alpha_Dorsal Stream Visual Cortex-rh: T1 = 24, T2 = 29\n",
      "Alpha_DorsoLateral Prefrontal Cortex-rh: T1 = 143, T2 = 137\n",
      "Alpha_Early Auditory Cortex-rh: T1 = 0, T2 = 0\n",
      "Alpha_Early Visual Cortex-rh: T1 = 22, T2 = 22\n",
      "Alpha_Inferior Frontal Cortex-rh: T1 = 279, T2 = 267\n",
      "Alpha_Inferior Parietal Cortex-rh: T1 = 22, T2 = 20\n",
      "Alpha_Insular and Frontal Opercular Cortex-rh: T1 = 0, T2 = 0\n",
      "Alpha_Lateral Temporal Cortex-rh: T1 = 9, T2 = 4\n",
      "Alpha_MT+ Complex and Neighboring Visual Areas-rh: T1 = 67, T2 = 64\n",
      "Alpha_Medial Temporal Cortex-rh: T1 = 0, T2 = 0\n",
      "Alpha_Orbital and Polar Frontal Cortex-rh: T1 = 275, T2 = 253\n",
      "Alpha_Paracentral Lobular and Mid Cingulate Cortex-rh: T1 = 7, T2 = 8\n",
      "Alpha_Posterior Cingulate Cortex-rh: T1 = 0, T2 = 0\n",
      "Alpha_Posterior Opercular Cortex-rh: T1 = 6, T2 = 6\n",
      "Alpha_Premotor Cortex-rh: T1 = 22, T2 = 17\n",
      "Alpha_Primary Visual Cortex (V1)-rh: T1 = 3, T2 = 2\n",
      "Alpha_Somatosensory and Motor Cortex-rh: T1 = 4, T2 = 1\n",
      "Alpha_Superior Parietal Cortex-rh: T1 = 57, T2 = 50\n",
      "Alpha_Temporo-Parieto-Occipital Junction-rh: T1 = 1, T2 = 2\n",
      "Alpha_Ventral Stream Visual Cortex-rh: T1 = 0, T2 = 0\n"
     ]
    }
   ],
   "source": [
    "# for all concepts, save the number of examples with T1 and T2\n",
    "for label in label_names:\n",
    "    for band in bands:\n",
    "        concept = band + '_' + label\n",
    "        path = DATA_PATH_CONCEPTS + concept + '/'\n",
    "        files = os.listdir(path)\n",
    "        T1 = 0\n",
    "        T2 = 0\n",
    "        for file in files:\n",
    "            if 'T1' in file:\n",
    "                T1 += 1\n",
    "            elif 'T2' in file:\n",
    "                T2 += 1\n",
    "        print(f'{concept}: T1 = {T1}, T2 = {T2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
