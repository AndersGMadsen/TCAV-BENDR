{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.getcwd().split(\"/\")[-1] != 'BENDR-XAI': os.chdir(\"../\")\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import animation\n",
    "import random\n",
    "import matplotlib.cm as cm\n",
    "import sys\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of path to all edf files in the subfolders of /nobackup/tsal-tmp/tuh_eeg\n",
    "# files = []\n",
    "\n",
    "# with tqdm() as pbar:\n",
    "#     for root, dirs, file in os.walk(\"/nobackup/tsal-tmp/tuh_eeg\"):\n",
    "#         for name in file:\n",
    "#             if name.endswith(\".edf\"):\n",
    "#                 files.append(os.path.join(root, name))\n",
    "#                 pbar.update(1)\n",
    "\n",
    "# Save list of files as pickle\n",
    "# import pickle\n",
    "# with open('tuh_files.pkl', 'wb') as f:\n",
    "#     pickle.dump(files, f)\n",
    "    \n",
    "# Load list of files from pickle\n",
    "# import pickle\n",
    "# with open('tuh_files.pkl', 'rb') as f:\n",
    "#     files = pickle.load(f)\n",
    "    \n",
    "# random.shuffle(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = []\n",
    "with open('tuh_final_selected.txt', 'r') as f:\n",
    "    selected.extend(f.read().splitlines())\n",
    "\n",
    "deselected = []\n",
    "with open('tuh_final_deselected.txt', 'r') as f:\n",
    "    deselected.extend(f.read().splitlines())\n",
    "\n",
    "# Open all the files tuh_selected*.txt, read the filesnames on each line and save them in one list\n",
    "files = []\n",
    "# for file in os.listdir():\n",
    "#     if file.startswith(\"tuh_selected\"):\n",
    "#         with open(file, 'r') as f:\n",
    "#             files_selected.extend(f.read().splitlines())\n",
    "files = ['data/tuh_eeg/' + file for file in os.listdir('data/tuh_eeg/')]\n",
    "files = [file for file in files if file not in selected and file not in deselected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all files in data/tuh_eeg/ that are not in selected\n",
    "for file in os.listdir('data/tuh_eeg/'):\n",
    "    if file not in selected and file not in deselected:\n",
    "        os.remove('data/tuh_eeg/' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: <object object at 0x7f84ac0d8360>\n",
      "Channels marked as bad:\n",
      "none\n",
      "Channels marked as bad:\n",
      "none\n",
      "Channels marked as bad:\n",
      "none\n",
      "Channels marked as bad:\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "%matplotlib auto\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read all files in tuh_final_selected.txt\n",
    "\n",
    "# Function to handle user input\n",
    "def on_key(event):\n",
    "    if event.key == 'y':\n",
    "        with open('tuh_final_selected.txt', 'a') as f:\n",
    "            f.write(current_file + '\\n')\n",
    "        \n",
    "        plt.close()\n",
    "    elif event.key == 'n':\n",
    "        with open('tuh_final_deselected.txt', 'a') as f:\n",
    "            f.write(current_file + '\\n')\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "# Iterate through the EDF files\n",
    "for file_path in files:\n",
    "    \n",
    "    if file_path in selected or file_path in deselected:\n",
    "        continue   \n",
    "    \n",
    "    # Load the EDF file using MNE\n",
    "    raw = mne.io.read_raw_edf(file_path, preload=True, verbose=False)\n",
    "    raw.resample(256, verbose=False)\n",
    "    raw.filter(1, 70, fir_design='firwin', verbose=False)\n",
    "    raw.notch_filter(60, fir_design='firwin', verbose=False)\n",
    "    \n",
    "    # Plot the data\n",
    "    fig = raw.plot(show=False, verbose=False, scalings='auto')\n",
    "    current_file = file_path\n",
    "    plt.title(f'File: {file_path}\\nPress \"y\" to save or any other key to skip')\n",
    "    \n",
    "    # Register the event handler and show the plot\n",
    "    cid = fig.canvas.mpl_connect('key_press_event', on_key)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('tuh_files.pkl', 'rb') as f:\n",
    "#     files = pickle.load(f)\n",
    "\n",
    "# Copy all files in tuh_final_selected.txt to data/tuh_eeg/\n",
    "# with open('tuh_final_selected.txt', 'r') as f:\n",
    "#     selected = f.read().splitlines()\n",
    "\n",
    "# selected = [file.split(\"/\")[-1] for file in selected]\n",
    "\n",
    "# Delete all files in /scratch/s194260/tuh_eeg/ that are not in selected\n",
    "# for file in os.listdir('/scratch/s194260/tuh_eeg/'):\n",
    "#     if file not in selected:\n",
    "#         os.remove('/scratch/s194260/tuh_eeg/' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m lengths \u001b[39m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m tqdm(os\u001b[39m.\u001b[39mlistdir(\u001b[39m'\u001b[39m\u001b[39m/scratch/s194260/tuh_eeg/\u001b[39m\u001b[39m'\u001b[39m)):\n\u001b[0;32m----> 4\u001b[0m     raw \u001b[39m=\u001b[39m mne\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mread_raw_edf(\u001b[39m'\u001b[39;49m\u001b[39m/scratch/s194260/tuh_eeg/\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m+\u001b[39;49m file, preload\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m      5\u001b[0m     raw\u001b[39m.\u001b[39mresample(\u001b[39m256\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m     lengths\u001b[39m.\u001b[39mappend(raw\u001b[39m.\u001b[39mn_times)\n",
      "File \u001b[0;32m~/.conda/envs/BENDR-XAI/lib/python3.10/site-packages/mne/io/edf/edf.py:1412\u001b[0m, in \u001b[0;36mread_raw_edf\u001b[0;34m(input_fname, eog, misc, stim_channel, exclude, infer_types, include, preload, units, encoding, verbose)\u001b[0m\n\u001b[1;32m   1410\u001b[0m \u001b[39mif\u001b[39;00m ext \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39medf\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m   1411\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mOnly EDF files are supported, got \u001b[39m\u001b[39m{\u001b[39;00mext\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1412\u001b[0m \u001b[39mreturn\u001b[39;00m RawEDF(input_fname\u001b[39m=\u001b[39;49minput_fname, eog\u001b[39m=\u001b[39;49meog, misc\u001b[39m=\u001b[39;49mmisc,\n\u001b[1;32m   1413\u001b[0m               stim_channel\u001b[39m=\u001b[39;49mstim_channel, exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[1;32m   1414\u001b[0m               infer_types\u001b[39m=\u001b[39;49minfer_types, preload\u001b[39m=\u001b[39;49mpreload, include\u001b[39m=\u001b[39;49minclude,\n\u001b[1;32m   1415\u001b[0m               units\u001b[39m=\u001b[39;49munits, encoding\u001b[39m=\u001b[39;49mencoding, verbose\u001b[39m=\u001b[39;49mverbose)\n",
      "File \u001b[0;32m<decorator-gen-244>:10\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, input_fname, eog, misc, stim_channel, exclude, infer_types, preload, include, units, encoding, verbose)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/BENDR-XAI/lib/python3.10/site-packages/mne/io/edf/edf.py:168\u001b[0m, in \u001b[0;36mRawEDF.__init__\u001b[0;34m(self, input_fname, eog, misc, stim_channel, exclude, infer_types, preload, include, units, encoding, verbose)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[39m# Raw attributes\u001b[39;00m\n\u001b[1;32m    167\u001b[0m last_samps \u001b[39m=\u001b[39m [edf_info[\u001b[39m'\u001b[39m\u001b[39mnsamples\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[0;32m--> 168\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(info, preload, filenames\u001b[39m=\u001b[39;49m[input_fname],\n\u001b[1;32m    169\u001b[0m                  raw_extras\u001b[39m=\u001b[39;49m[edf_info], last_samps\u001b[39m=\u001b[39;49mlast_samps,\n\u001b[1;32m    170\u001b[0m                  orig_format\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mint\u001b[39;49m\u001b[39m'\u001b[39;49m, orig_units\u001b[39m=\u001b[39;49morig_units,\n\u001b[1;32m    171\u001b[0m                  verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m    173\u001b[0m \u001b[39m# Read annotations from file and set it\u001b[39;00m\n\u001b[1;32m    174\u001b[0m onset, duration, desc \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(), \u001b[39mlist\u001b[39m(), \u001b[39mlist\u001b[39m()\n",
      "File \u001b[0;32m<decorator-gen-222>:10\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, info, preload, first_samps, last_samps, filenames, raw_extras, orig_format, dtype, buffer_size_sec, orig_units, verbose)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/BENDR-XAI/lib/python3.10/site-packages/mne/io/base.py:227\u001b[0m, in \u001b[0;36mBaseRaw.__init__\u001b[0;34m(self, info, preload, first_samps, last_samps, filenames, raw_extras, orig_format, dtype, buffer_size_sec, orig_units, verbose)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39m# If we have True or a string, actually do the preloading\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[39mif\u001b[39;00m load_from_disk:\n\u001b[0;32m--> 227\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_preload_data(preload)\n\u001b[1;32m    228\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_kwargs \u001b[39m=\u001b[39m _get_argvalues()\n",
      "File \u001b[0;32m~/.conda/envs/BENDR-XAI/lib/python3.10/site-packages/mne/io/base.py:507\u001b[0m, in \u001b[0;36mBaseRaw._preload_data\u001b[0;34m(self, preload)\u001b[0m\n\u001b[1;32m    504\u001b[0m     data_buffer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    505\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mReading \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m ... \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m  =  \u001b[39m\u001b[39m%9.3f\u001b[39;00m\u001b[39m ... \u001b[39m\u001b[39m%9.3f\u001b[39;00m\u001b[39m secs...\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m    506\u001b[0m             (\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimes) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m0.\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimes[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]))\n\u001b[0;32m--> 507\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_segment(\n\u001b[1;32m    508\u001b[0m     data_buffer\u001b[39m=\u001b[39;49mdata_buffer, projector\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_projector)\n\u001b[1;32m    509\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data) \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo[\u001b[39m'\u001b[39m\u001b[39mnchan\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    510\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreload \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m<decorator-gen-224>:12\u001b[0m, in \u001b[0;36m_read_segment\u001b[0;34m(self, start, stop, sel, data_buffer, projector, verbose)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/BENDR-XAI/lib/python3.10/site-packages/mne/io/base.py:392\u001b[0m, in \u001b[0;36mBaseRaw._read_segment\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[39m# reindex back to original file\u001b[39;00m\n\u001b[1;32m    391\u001b[0m     orig_idx \u001b[39m=\u001b[39m _convert_slice(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_picks[fi][need_idx])\n\u001b[0;32m--> 392\u001b[0m     _ReadSegmentFileProtector(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_read_segment_file(\n\u001b[1;32m    393\u001b[0m         data[:, this_sl], orig_idx, fi,\n\u001b[1;32m    394\u001b[0m         \u001b[39mint\u001b[39;49m(start_file), \u001b[39mint\u001b[39;49m(stop_file), cals, mult)\n\u001b[1;32m    395\u001b[0m     offset \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m n_read\n\u001b[1;32m    396\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.conda/envs/BENDR-XAI/lib/python3.10/site-packages/mne/io/base.py:2145\u001b[0m, in \u001b[0;36m_ReadSegmentFileProtector._read_segment_file\u001b[0;34m(self, data, idx, fi, start, stop, cals, mult)\u001b[0m\n\u001b[1;32m   2144\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_segment_file\u001b[39m(\u001b[39mself\u001b[39m, data, idx, fi, start, stop, cals, mult):\n\u001b[0;32m-> 2145\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__raw\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49m_read_segment_file(\n\u001b[1;32m   2146\u001b[0m         \u001b[39mself\u001b[39;49m, data, idx, fi, start, stop, cals, mult)\n",
      "File \u001b[0;32m~/.conda/envs/BENDR-XAI/lib/python3.10/site-packages/mne/io/edf/edf.py:191\u001b[0m, in \u001b[0;36mRawEDF._read_segment_file\u001b[0;34m(self, data, idx, fi, start, stop, cals, mult)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_segment_file\u001b[39m(\u001b[39mself\u001b[39m, data, idx, fi, start, stop, cals, mult):\n\u001b[1;32m    190\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Read a chunk of raw data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m     \u001b[39mreturn\u001b[39;00m _read_segment_file(data, idx, fi, start, stop,\n\u001b[1;32m    192\u001b[0m                               \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raw_extras[fi], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_filenames[fi],\n\u001b[1;32m    193\u001b[0m                               cals, mult)\n",
      "File \u001b[0;32m~/.conda/envs/BENDR-XAI/lib/python3.10/site-packages/mne/io/edf/edf.py:372\u001b[0m, in \u001b[0;36m_read_segment_file\u001b[0;34m(data, idx, fi, start, stop, raw_extras, filenames, cals, mult)\u001b[0m\n\u001b[1;32m    365\u001b[0m         ch_data \u001b[39m=\u001b[39m interp1d(old, ch_data,\n\u001b[1;32m    366\u001b[0m                            kind\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mzero\u001b[39m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)(new)\n\u001b[1;32m    367\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    368\u001b[0m         \u001b[39m# XXX resampling each chunk isn't great,\u001b[39;00m\n\u001b[1;32m    369\u001b[0m         \u001b[39m# it forces edge artifacts to appear at\u001b[39;00m\n\u001b[1;32m    370\u001b[0m         \u001b[39m# each buffer boundary :(\u001b[39;00m\n\u001b[1;32m    371\u001b[0m         \u001b[39m# it can also be very slow...\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m         ch_data \u001b[39m=\u001b[39m resample(\n\u001b[1;32m    373\u001b[0m             ch_data\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49mfloat64), buf_len, n_samps[ci],\n\u001b[1;32m    374\u001b[0m             npad\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    375\u001b[0m \u001b[39melif\u001b[39;00m orig_idx \u001b[39min\u001b[39;00m stim_channel_idxs:\n\u001b[1;32m    376\u001b[0m     ch_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mbitwise_and(ch_data\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m), \u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m17\u001b[39m \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m<decorator-gen-146>:12\u001b[0m, in \u001b[0;36mresample\u001b[0;34m(x, up, down, npad, axis, window, n_jobs, pad, verbose)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/BENDR-XAI/lib/python3.10/site-packages/mne/filter.py:1511\u001b[0m, in \u001b[0;36mresample\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39mlen\u001b[39m(x_flat), new_len \u001b[39m-\u001b[39m to_removes\u001b[39m.\u001b[39msum()), dtype\u001b[39m=\u001b[39mx\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m   1510\u001b[0m     \u001b[39mfor\u001b[39;00m xi, x_ \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(x_flat):\n\u001b[0;32m-> 1511\u001b[0m         y[xi] \u001b[39m=\u001b[39m _fft_resample(x_, new_len, npads, to_removes,\n\u001b[1;32m   1512\u001b[0m                               cuda_dict, pad)\n\u001b[1;32m   1513\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1514\u001b[0m     y \u001b[39m=\u001b[39m parallel(p_fun(x_, new_len, npads, to_removes, cuda_dict, pad)\n\u001b[1;32m   1515\u001b[0m                  \u001b[39mfor\u001b[39;00m x_ \u001b[39min\u001b[39;00m x_flat)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get length of all edf files in /scratch/s194260/tuh_eeg/\n",
    "lengths = []\n",
    "for file in tqdm(os.listdir('/scratch/s194260/tuh_eeg/')):\n",
    "    raw = mne.io.read_raw_edf('/scratch/s194260/tuh_eeg/' + file, preload=True, verbose=False)\n",
    "    raw.resample(256, verbose=False)\n",
    "    lengths.append(raw.n_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from notebooks.utils import *\n",
    "\n",
    "from matplotlib import animation\n",
    "import matplotlib.cm as cm\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import multiprocessing\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fp1',\n",
       " 'Fp2',\n",
       " 'F3',\n",
       " 'F4',\n",
       " 'C3',\n",
       " 'C4',\n",
       " 'P3',\n",
       " 'P4',\n",
       " 'O1',\n",
       " 'O2',\n",
       " 'F7',\n",
       " 'F8',\n",
       " 'T7',\n",
       " 'T8',\n",
       " 'P7',\n",
       " 'P8',\n",
       " 'FT9',\n",
       " 'FT10',\n",
       " 'Fz',\n",
       " 'Pz',\n",
       " 'Cz']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(channel_positions.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /scratch/s194260/tuh_eeg/aaaaamhf_s007_t026.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 77055  =      0.000 ...   300.996 secs...\n"
     ]
    }
   ],
   "source": [
    "file_path = '/scratch/s194260/tuh_eeg/' + file\n",
    "\n",
    "raw = mne.io.read_raw_edf(file_path, preload=True, verbose=True)\n",
    "mne.datasets.eegbci.standardize(raw)\n",
    "raw = raw.set_eeg_reference(ref_channels='average', projection=True, verbose = False)\n",
    "\n",
    "# Channel positions dictionary (subset)\n",
    "channel_positions = {\n",
    "    'EEG FP1-REF': 'Fp1',\n",
    "    'EEG FP2-REF': 'Fp2',\n",
    "    'EEG F3-REF': 'F3',\n",
    "    'EEG F4-REF': 'F4',\n",
    "    'EEG C3-REF': 'C3',\n",
    "    'EEG C4-REF': 'C4',\n",
    "    'EEG P3-REF': 'P3',\n",
    "    'EEG P4-REF': 'P4',\n",
    "    'EEG O1-REF': 'O1',\n",
    "    'EEG O2-REF': 'O2',\n",
    "    'EEG F7-REF': 'F7',\n",
    "    'EEG F8-REF': 'F8',\n",
    "    'EEG T3-REF': 'T7',\n",
    "    'EEG T4-REF': 'T8',\n",
    "    'EEG T5-REF': 'P7',\n",
    "    'EEG T6-REF': 'P8',\n",
    "    'EEG T1-REF': 'FT9',\n",
    "    'EEG T2-REF': 'FT10',\n",
    "    'EEG FZ-REF': 'Fz',\n",
    "    'EEG CZ-REF': 'Cz',\n",
    "    'EEG PZ-REF': 'Pz',\n",
    "}   \n",
    "\n",
    "\n",
    "# Create the custom montage\n",
    "ten_twenty_montage = mne.channels.make_standard_montage('standard_1020')\n",
    "\n",
    "# Rename channels and set the custom montage\n",
    "raw = raw.rename_channels(channel_positions)\n",
    "raw = raw.set_montage(ten_twenty_montage, on_missing='ignore')\n",
    "\n",
    "# Set channel types for non-EEG channels\n",
    "non_eeg_channels = {\n",
    "    'EEG EKG1-REF': 'ecg',\n",
    "    'EMG-REF': 'emg',\n",
    "    'PHOTIC-REF': 'misc',\n",
    "    'IBI': 'misc',\n",
    "    'BURSTS': 'misc',\n",
    "    'SUPPR': 'misc',\n",
    "    'EEG A1-REF': 'eog',\n",
    "    'EEG A2-REF': 'eog',\n",
    "    'EEG 31-REF': 'eog',\n",
    "    'EEG 32-REF': 'eog',\n",
    "    'EEG C3P-REF': 'eog',\n",
    "    'EEG C4P-REF': 'eog',\n",
    "    'EEG SP1-REF': 'eog',\n",
    "    'EEG SP2-REF': 'eog',\n",
    "}\n",
    "\n",
    "#raw = raw.set_channel_types(non_eeg_channels, on_missing='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_dir, subject, trans, src_path, bem_path = get_fsaverage()\n",
    "src = get_src(src_path)\n",
    "fwd = get_fwd(raw.info, trans, src_path, bem_path)\n",
    "cov = get_cov(raw)\n",
    "compute_inverse = make_fast_inverse_operator(raw.info, fwd, cov, snr=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of raw: 301.0 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of raw: {raw.n_times / raw.info[\"sfreq\"]} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SourceEstimate | 20484 vertices, subject : fsaverage, tmin : 0.0 (ms), tmax : 300996.09375 (ms), tstep : 3.90625 (ms), data shape : (20484, 77056), ~11.76 GB>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_inverse(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "SSP projectors applied...\n"
     ]
    }
   ],
   "source": [
    "raw = mne.io.read_raw_edf('data/eegmmidb/files/S003/S003R01.edf', verbose=False, preload=True)\n",
    "# Apply average reference if not already applied\n",
    "if not raw.info['custom_ref_applied']:\n",
    "    raw.set_eeg_reference(ref_channels='average', projection=True, verbose = False)\n",
    "    # applt projection\n",
    "    raw.apply_proj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw1 = mne.io.read_raw_edf('data/eegmmidb/files/S003/S003R01.edf', verbose=False, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.7406250e-05, 1.1237500e-04, 1.0971875e-04, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [5.1406250e-05, 8.9375000e-05, 7.7718750e-05, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [7.7406250e-05, 1.0637500e-04, 1.0771875e-04, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       ...,\n",
       "       [6.2406250e-05, 6.2375000e-05, 4.7718750e-05, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [6.5406250e-05, 6.8375000e-05, 5.5718750e-05, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [7.3406250e-05, 6.9375000e-05, 5.3718750e-05, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.53e-04, 1.77e-04, 1.30e-04, ..., 0.00e+00, 0.00e+00, 0.00e+00],\n",
       "       [1.47e-04, 1.54e-04, 9.80e-05, ..., 0.00e+00, 0.00e+00, 0.00e+00],\n",
       "       [1.73e-04, 1.71e-04, 1.28e-04, ..., 0.00e+00, 0.00e+00, 0.00e+00],\n",
       "       ...,\n",
       "       [1.58e-04, 1.27e-04, 6.80e-05, ..., 0.00e+00, 0.00e+00, 0.00e+00],\n",
       "       [1.61e-04, 1.33e-04, 7.60e-05, ..., 0.00e+00, 0.00e+00, 0.00e+00],\n",
       "       [1.69e-04, 1.34e-04, 7.40e-05, ..., 0.00e+00, 0.00e+00, 0.00e+00]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw1.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Info | 8 non-empty values\n",
      " bads: []\n",
      " ch_names: EEG FP1-REF, EEG FP2-REF, EEG F3-REF, EEG F4-REF, EEG C3-REF, ...\n",
      " chs: 35 EEG\n",
      " custom_ref_applied: False\n",
      " highpass: 0.0 Hz\n",
      " lowpass: 128.0 Hz\n",
      " meas_date: 2012-01-26 07:50:43 UTC\n",
      " nchan: 35\n",
      " projs: Average EEG reference: off\n",
      " sfreq: 256.0 Hz\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "print(raw.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Info | 7 non-empty values\n",
      " bads: []\n",
      " ch_names: Fc5., Fc3., Fc1., Fcz., Fc2., Fc4., Fc6., C5.., C3.., C1.., ...\n",
      " chs: 64 EEG\n",
      " custom_ref_applied: False\n",
      " highpass: 0.0 Hz\n",
      " lowpass: 80.0 Hz\n",
      " meas_date: 2009-08-12 16:15:00 UTC\n",
      " nchan: 64\n",
      " projs: []\n",
      " sfreq: 160.0 Hz\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "print(mne.io.read_raw_edf('data/eegmmidb/files/S003/S003R01.edf', verbose=False, preload=True).info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
